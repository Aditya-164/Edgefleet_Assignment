# Cricket Ball Detection & Tracking System ğŸ

A computer vision pipeline built for the **EdgeFleet.AI Assessment**. This system detects and tracks cricket balls in video footage using **YOLOv8** and generates trajectory analytics.

## ğŸ“Œ Project Overview

- **Goal:** Detect ball centroid and track trajectory in single-camera footage.

- **Model:** Custom trained YOLOv8 Nano.

- **Input:** Raw MP4/MOV cricket videos.

- **Output:** Processed video with overlay + CSV annotation file.

## ğŸ“‚ Repository Structure

EdgeFleet_Assessment/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ train.py          # Training script (Transfer Learning with YOLOv8)
â”‚   â”œâ”€â”€ inference.py      # Main pipeline (Detection + Tracking + Smoothing)
â”‚   â””â”€â”€ create_subset.py  # Utility script for dataset management
â”‚
â”œâ”€â”€ annotations/          # Generated CSV files (tracking & smoothing outputs)
â”œâ”€â”€ results/              # Output processed videos
â”œâ”€â”€ models/               # Trained YOLOv8 weights (best.pt)
â”‚
â”œâ”€â”€ Report.pdf            # Detailed technical report
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation


## ğŸš€ Setup & Usage

### 1. Installation

Clone the repository and install dependencies:

```bash

git clone https://github.com/Aditya-164/Edgefleet_Assignment.git

cd Edgefleet_Assignment

pip install -r requirements.txt
2. Inference (Running on Test Videos)
To generate annotations and tracking videos for the test set:

Place input videos in a folder named test_videos/ (outside the repo to save space) or update path in inference.py.
Run the script:

cd code

python inference.py

Results will be saved to results/ and annotations/.
3. Training (Reproducibility)
To replicate the training process:

Download the "Cricket Ball" dataset from Roboflow (YOLOv8 format).
Update dataset/data.yaml paths.
Run:

cd code

python train.py
ğŸ§  Methodology
Data Strategy: Trained on an external open-source dataset (1,500 images) to prevent data leakage from test videos.
Filtering: Implemented Spatial Consistency Checks to reject false positives (e.g., white shoes) based on unrealistic movement speed.
Smoothing: Uses linear interpolation to fill missing detections during motion blur.
ğŸ“ Limitations
Trained on CPU with a subset of data. Full GPU training on the complete dataset would further improve accuracy.
Simple physics-based tracking used; Kalman filters recommended for production V2.

---

